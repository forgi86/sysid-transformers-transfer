{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df653a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dataset import WHDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from transformer_sim import Config, TSTransformer\n",
    "import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad041070",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_path = Path(\"fig\")\n",
    "fig_path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a10f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix all random sources to make script fully reproducible\n",
    "torch.manual_seed(420)\n",
    "np.random.seed(430)\n",
    "system_seed = 430 # Controls the system generation\n",
    "data_seed = 0 # Controls the input generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a235fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall settings\n",
    "out_dir = \"out\"\n",
    "\n",
    "# System settings\n",
    "nu = 1\n",
    "ny = 1\n",
    "#seq_len = 600\n",
    "batch_size = 32 # 256\n",
    "fixed_system = False # Are we testing on a fixed system?\n",
    "\n",
    "# Compute settings\n",
    "cuda_device = \"cuda:0\"\n",
    "no_cuda = True\n",
    "threads = 5\n",
    "compile = False\n",
    "\n",
    "# Configure compute\n",
    "torch.set_num_threads(threads) \n",
    "use_cuda = not no_cuda and torch.cuda.is_available()\n",
    "device_name  = cuda_device if use_cuda else \"cpu\"\n",
    "device = torch.device(device_name)\n",
    "device_type = 'cuda' if 'cuda' in device_name else 'cpu' # for later use in torch.autocast\n",
    "torch.set_float32_matmul_precision(\"high\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ad2d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create out dir\n",
    "out_dir = Path(out_dir)\n",
    "exp_data = torch.load(out_dir / \"ckpt_sim_wh.pt\", map_location=device)\n",
    "cfg = exp_data[\"cfg\"]\n",
    "# For compatibility with initial experiment without seed\n",
    "try:\n",
    "    cfg.seed\n",
    "except AttributeError:\n",
    "    cfg.seed = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c029f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = cfg.seq_len_ctx + cfg.seq_len_new\n",
    "nx = cfg.nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29395ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_smooth = pd.Series(exp_data[\"LOSS\"]).rolling(100).mean()\n",
    "plt.figure()\n",
    "plt.plot(exp_data[\"LOSS\"], label=\"TRAINING_LOSS\")\n",
    "plt.plot(loss_smooth, label=\"TRAINING_LOSS_SMOOTH\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34332c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = exp_data[\"model_args\"]\n",
    "conf = Config(**model_args)\n",
    "model = TSTransformer(conf).to(device)\n",
    "model.load_state_dict(exp_data[\"model\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e08b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loader\n",
    "test_ds = WHDataset(nx=nx, nu=nu, ny=ny, seq_len=seq_len,\n",
    "                    system_seed=cfg.seed if fixed_system else system_seed,\n",
    "                    data_seed=0, fixed_system=fixed_system)\n",
    "#test_ds = LinearDynamicalDataset(nx=cfg.nx, nu=cfg.nu, ny=cfg.ny, seq_len=cfg.seq_len_ctx+cfg.seq_len_new)\n",
    "test_dl = DataLoader(test_ds, batch_size=batch_size, num_workers=threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f80625a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_y, batch_u = next(iter(test_dl))\n",
    "batch_y = batch_y.to(device)\n",
    "batch_u = batch_u.to(device)\n",
    "with torch.no_grad():\n",
    "    batch_y_ctx = batch_y[:, :cfg.seq_len_ctx, :]\n",
    "    batch_u_ctx = batch_u[:, :cfg.seq_len_ctx, :]\n",
    "    batch_y_new = batch_y[:, cfg.seq_len_ctx:, :]\n",
    "    batch_u_new = batch_u[:, cfg.seq_len_ctx:, :]\n",
    "    batch_y_sim = model(batch_y_ctx, batch_u_ctx, batch_u_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6eef187",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_y_sim = batch_y_sim.to(\"cpu\").detach().numpy()\n",
    "batch_y_new = batch_y_new.to(\"cpu\").detach().numpy()\n",
    "batch_u_new = batch_u_new.to(\"cpu\").detach().numpy()\n",
    "batch_sim_err = batch_y_new[:, :, :] - batch_y_sim[:, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7225d5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.arange(1, batch_u_new.shape[1]+1) + cfg.seq_len_ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe4be88",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 2.5))\n",
    "idx = 1\n",
    "plt.plot(t, batch_y_new[idx, :, :], 'k', label=\"$y$\")\n",
    "plt.plot(t, batch_y_sim[idx, :, :], 'b', label=\"$\\hat y$\")\n",
    "plt.plot(t, batch_sim_err[idx, :, :], 'r', label=\"$y - \\hat y$\")\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"time step (-)\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.tight_layout()\n",
    "plt.savefig(fig_path / \"wh_sim_single.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2aab2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 2.5))\n",
    "#plt.ylim([-3, 3])\n",
    "plt.plot(t, batch_y_new.squeeze(-1).T, \"k\", alpha=0.5);\n",
    "plt.plot(t, np.nan*np.zeros(t.shape), \"k\", alpha=1.0, label=\"$y$\")\n",
    "plt.plot(t, batch_sim_err.squeeze(-1).T, \"r\", alpha=0.2);\n",
    "plt.plot(t, np.nan*np.zeros(t.shape), \"r\", alpha=1.0, label=\"$y - \\hat y$\");\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"time step (-)\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.tight_layout()\n",
    "plt.savefig(fig_path / \"wh_sim_batch.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6380a26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "skip = 0\n",
    "rmse = metrics.rmse(batch_y_new, batch_y_sim, time_axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce75ff31",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'iterations: {exp_data[\"cfg\"].max_iters}')\n",
    "print(f'train_time: {exp_data[\"train_time\"]/3600/24} days')\n",
    "print(f'rmse: {rmse.mean()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
